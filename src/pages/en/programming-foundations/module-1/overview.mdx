---
title: Programming foundations overview
description: Overview of the course and how to get started
tags: Programming Foundations
layout: ../../../../layouts/MainLayout.astro
---

## Introduction

Programming is the act of writing a series of instructions for a computer to carry out. Imagine a pocket calculator sitting on a desk. It is capable of performing a huge range of tasks, but will not do anything until its buttons are pressed. A computer behaves in the same way; each thread within the processor can only perform one calculation at one time, producing a single result.

Fundamentally, a computer can only perform four operations: `addition`, `subtraction`, `multiplication` and `division`. Every other operation is created using a series of these `logical` building blocks. For example, `squaring` involves two rounds of `multiplication`. To average a set of numbers would involve many rounds of `addition` and one round of `division`.

Computers can only interpret `numbers` represented as `binary` (Base 2), which is written in `0`s and `1`s. Most cultures use a base 10 counting system, and thinking in terms of another can be quite difficult. Thankfully, we do not have to learn how to perform mathematics in Base 2 in order to write software. This is the purpose of a `programming language`, to convert a human-friendly input into a computer-friendly output.

As we are social creatures that communicate with speech, this is the most friendly format for us to read and write code with. To be specific, we use a format called `logic` to describe instructions to the computer. The language of `logic` is intentionally similar to plain English to make it as easy as possible to learn and work with. No coding knowledge is required to read and write logic:
